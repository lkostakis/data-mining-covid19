{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We create the initial array at first, for both versions of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie 1</th>\n",
       "      <th>Movie 2</th>\n",
       "      <th>Movie 3</th>\n",
       "      <th>Movie 4</th>\n",
       "      <th>Movie 5</th>\n",
       "      <th>Movie 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User X</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Y</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Z</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User W</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Movie 1  Movie 2  Movie 3  Movie 4  Movie 5  Movie 6\n",
       "User X      5.0      3.0      NaN      1.0      NaN      NaN\n",
       "User Y      4.0      2.0      1.0      NaN      NaN      1.0\n",
       "User Z      3.0      NaN      NaN      1.0      3.0      3.0\n",
       "User W      2.0      5.0      1.0      5.0      3.0      4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating the database with the ratings\n",
    "user_ratings = pd.DataFrame({'Movie 1':[5.0, 4.0, 3.0, 2.0], 'Movie 2': [3, 2, None, 5],\n",
    "                             'Movie 3':[None, 1, None, 1], 'Movie 4': [1, None, 1, 5],\n",
    "                             'Movie 5': [None, None, 3, 3], 'Movie 6': [None, 1, 3, 4]},\n",
    "                             index = ['User X', 'User Y', 'User Z', 'User W'])\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the first version of algorithm.\n",
    "In the first version, we will calculate the cosine similarity between user X and the other users, and we will calculate the score for cell (X, 6) as the weighted average of the score of the two most similar users in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------------------+--------------------+--------------------+\n",
      "| Similarities | User X |       User Y       |       User Z       |       User W       |\n",
      "+--------------+--------+--------------------+--------------------+--------------------+\n",
      "|    User X    |  1.0   | 0.9369749612033813 | 0.5111012519999519 | 0.5669467095138409 |\n",
      "+--------------+--------+--------------------+--------------------+--------------------+\n",
      "\n",
      "\u001b[1m\u001b[4mThe prediction for the review (X,6) is:\u001b[1m\u001b[0m 2.1309366449453377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import heapq\n",
    "\n",
    "A =  np.array([user_ratings.loc['User X'].values,\n",
    "               user_ratings.loc['User Y'].values,\n",
    "               user_ratings.loc['User Z'].values,\n",
    "               user_ratings.loc['User W'].values])\n",
    "\n",
    "A_sparse = sparse.csr_matrix(A)\n",
    "A_sparse = np.nan_to_num(A_sparse.toarray())\n",
    "\n",
    "similarities = cosine_similarity(A_sparse)\n",
    "\n",
    "# Print Similarity table for User X\n",
    "from prettytable import PrettyTable\n",
    "t = PrettyTable(['Similarities','User X', 'User Y', 'User Z', 'User W'])\n",
    "t.add_row(['User X', similarities[0][0], similarities[0][1], similarities[0][2], similarities[0][3]])\n",
    "print(t)\n",
    "\n",
    "# Get the 2 largest values and its' index value\n",
    "index = heapq.nlargest(2, range(1,len(similarities[0])), similarities[0].take)\n",
    "values = [similarities[0][index[0]], similarities[0][index[1]]]\n",
    "prediction = values[0]*user_ratings.iloc[index[0]].values[5] + values[1]*user_ratings.iloc[index[1]].values[5]\n",
    "prediction /= values[0]+values[1]\n",
    "print('\\n'+'\\033[1m'+'\\033[4m'+'The prediction for the review (X,6) is:'+'\\033[1m'+'\\033[0m', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the second version of algorithm.\n",
    "We will first subtract the average value of the scores from each line (will use only non-zero values), then again calculate the cosine similarity of user X with other users, and now calculate the deviation from the mean for cell (X, 6) to the weighted average of the deviation of the two most similar users to X. Finally, we calculate the score by adding the deviation we calculated to the mean value of user X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[4mUser ratings subtracting each rows' mean value:\u001b[1m\u001b[0m\n",
      "         Movie 1   Movie 2   Movie 3   Movie 4   Movie 5   Movie 6\n",
      "User X  2.000000  0.000000       NaN -2.000000       NaN       NaN\n",
      "User Y  2.000000  0.000000 -1.000000       NaN       NaN -1.000000\n",
      "User Z  0.500000       NaN       NaN -1.500000  0.500000  0.500000\n",
      "User W -1.333333  1.666667 -2.333333  1.666667 -0.333333  0.666667\n",
      "\n",
      "\u001b[1m\u001b[4mSimilarity table for User X\u001b[1m\u001b[0m\n",
      "+--------------+--------------------+--------------------+-------------------+---------------------+\n",
      "| Similarities |       User X       |       User Y       |       User Z      |        User W       |\n",
      "+--------------+--------------------+--------------------+-------------------+---------------------+\n",
      "|    User X    | 0.9999999999999998 | 0.5773502691896258 | 0.816496580927726 | -0.5809475019311124 |\n",
      "+--------------+--------------------+--------------------+-------------------+---------------------+\n",
      "\n",
      "\u001b[1m\u001b[4mThe prediction for the review (X,6) is:\u001b[1m\u001b[0m 2.878679656440357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import heapq\n",
    "\n",
    "mean_ratings_dev = user_ratings.sub(user_ratings.mean(axis = 1, skipna = True), axis = 0)\n",
    "print('\\n'+'\\033[1m'+'\\033[4m'+'User ratings subtracting each rows\\' mean value:'+'\\033[1m'+'\\033[0m')\n",
    "print(mean_ratings_dev)\n",
    "\n",
    "A =  np.array([mean_ratings_dev.loc['User X'].values,\n",
    "               mean_ratings_dev.loc['User Y'].values,\n",
    "               mean_ratings_dev.loc['User Z'].values,\n",
    "               mean_ratings_dev.loc['User W'].values])\n",
    "\n",
    "A_sparse = sparse.csr_matrix(A)\n",
    "A_sparse = np.nan_to_num(A_sparse.toarray())\n",
    "\n",
    "similarities = cosine_similarity(A_sparse)\n",
    "# Print Similarity table for User X\n",
    "from prettytable import PrettyTable\n",
    "t = PrettyTable(['Similarities','User X', 'User Y', 'User Z', 'User W'])\n",
    "t.add_row(['User X', similarities[0][0], similarities[0][1], similarities[0][2], similarities[0][3]])\n",
    "print('\\n'+'\\033[1m'+'\\033[4m'+'Similarity table for User X'+'\\033[1m'+'\\033[0m')\n",
    "print(t)\n",
    "\n",
    "index = heapq.nlargest(2, range(1,len(similarities[0])), similarities[0].take)\n",
    "values = [similarities[0][index[0]], similarities[0][index[1]]]\n",
    "\n",
    "prediction = values[0]*mean_ratings_dev.iloc[index[0]].values[5] + values[1]*mean_ratings_dev.iloc[index[1]].values[5]\n",
    "prediction /= values[0]+values[1]\n",
    "prediction += user_ratings.loc['User X'].mean(skipna = True)\n",
    "print('\\n'+'\\033[1m'+'\\033[4m'+'The prediction for the review (X,6) is:'+'\\033[1m'+'\\033[0m',prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "## Results and algorithms analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\;\\;\\;$We notice that there is a significant difference in the two cases, this is because in the first version of the algorithm we calculate the estimate (Χ,6) based on user ratings, while in the second we get the deviation from the average value of ratings for each user.<br><br>\n",
    "$\\;\\;\\;$Thus, for each case the cosine similarities are different.\n",
    "In the first version the users with the greatest similarity are Υ with cos_sim(X,Y)=0,93 and user W with cos_sim(X,W)=0.56, while in the second version are users Ζ and Υ with cos_sim(X,Z)=0.81 and cos(X,Y)=0.57 respectively.\n",
    "\n",
    "\n",
    "$\\;\\;\\;$These changes exist because each version 'works' differently. Specifically for the first version, the similarity is calculated based on the values of the scores, while in the second, the similarity between the standard deviation of the scores plays a role. \n",
    "\n",
    "$\\;\\;\\;$In the first version the users with the greatest weight in terms of the result are Y=1 and W=4 with Υ having higher weight cos_sim(X,Y)=0.936 than user W with cos_sim(X,W)=0,56. In the case that we look user Y in relation to user X, is very similar because in the same movies they have given similar scores, for 'Movie 1' X and Y have scored 5 and 4 respectively as well as in movie 2 they have given 3 and 2 respectively, so the numerator in the formula of similarity increases significantly. However, this does not apply to user W in relation to user X, where they have rated the same movies with quite different ratings. User X gives 5 and 3 as we said for 'Movie 1' and 'Movie 2', while user W with 2 and 5 respectively. In movie 6, Y gives 1 and user W 4, so intuitively we could say that the score will be clearly closer to that given by user Y than the user W. And so it is with 2.13.<br>\n",
    "\n",
    "$\\;\\;\\;$In the second case we look at different users. The biggest similarity with user X, have the users Z with value 0.816 and user Y with 0.577. Here user Z influences user X more and gives a score of 0.5 (with the new table) for movie 6 with movies having the greatest impact are 'Movie 1', 'Movie 5' and 'Movie 6' because they give a very small standard deviation, being more consistent in his choices and thus there is greater similarity. User Y gives -1. Therefore the score should be closer to that of user Ζ and in combination with the negative rating given by Υ the predicted review is 2.87."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
